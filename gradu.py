# Define the initial parameters
theta = 0.0

# Define the learning rate
learning_rate = 0.1

# Define the gradient of the objective function
gradient = 1.0

# Perform the gradient update
theta_updated = theta - learning_rate * gradient

# Print the updated parameters
print("Updated theta:", theta_updated)

